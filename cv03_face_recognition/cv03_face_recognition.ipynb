{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "В рамках выполнения данного задания вам необходимо обучить нейросетевую модель распознавания лиц\n",
    "\n",
    "В качестве результата свой работы вам нужно предоставить файл classifier.py с классом Classifier внутри\n",
    "В методе `__init__` данного класса должна происходить инициализация сети\n",
    "Также у класса должен быть метод `calculate_descriptors`, который должен принимать на вход батч нормализованных изображений, а на выходе возвращать тензор с дескрипторами для всех изображений в батче\n",
    "\n",
    "15 баллов вы получите за результат, который на тестовой выборке будет превосходить результаты baseline'а\n",
    "3 лучших решения так же получат дополнительные баллы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install mxnet timm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'bilinear'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloader CASIA-WebFace"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/deepinsight/insightface.git"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!gdown 1LQHRJG7gUNWe4gIRK1jfrhImR7SOjOuF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip faces_webface_112x112.zip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys ; sys.path.append('insightface/recognition/arcface_torch')\n",
    "from insightface.recognition.arcface_torch.dataset import get_dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(\n",
    "    root_dir='faces_webface_112x112',\n",
    "    local_rank=0,\n",
    "    batch_size=256,\n",
    "    num_workers=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for imgs, labels in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(((imgs[0] + 1) / 2).detach().cpu().numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Код нормализации изображений: https://github.com/davidsandberg/facenet/tree/master/src/align"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-56-6ce71640ed4b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-56-6ce71640ed4b>\"\u001B[0;36m, line \u001B[0;32m1\u001B[0m\n\u001B[0;31m    Код нормализации изображений: https://github.com/davidsandberg/facenet/tree/master/src/align\u001B[0m\n\u001B[0m                   ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model, loss, optimizer preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import timm\n",
    "model = timm.create_model(\n",
    "    'resnet50',\n",
    "    pretrained=True,\n",
    "    num_classes=10572\n",
    ").cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_CE = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opt_parameters = model.parameters()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    opt_parameters,\n",
    "    lr=1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "lr_scale_change = 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "step, n_steps = 0, EPOCHS * len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(imgs)\n",
    "\n",
    "        loss = loss_CE(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "        if step % 100 == 0:\n",
    "            print(f'Step {step}/{n_steps}, loss {loss}')\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_scale_change"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fc = Identity()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = torch.load(model_path)\n",
    "        self.model.eval()\n",
    "\n",
    "    def calculate_descriptors(self, imgs):\n",
    "        return self.model(imgs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = Classifier('model.pth')\n",
    "descriptors = classifier.calculate_descriptors(imgs)\n",
    "descriptors = descriptors.detach().cpu().numpy()\n",
    "descriptors = sklearn.preprocessing.normalize(descriptors)\n",
    "print(descriptors.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distances = sklearn.metrics.pairwise_distances(descriptors)\n",
    "print(distances.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distances[np.tril_indices(distances.shape[0])] = np.inf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_idxs = np.unravel_index(distances.argmin(), distances.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distances[min_idxs]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(((imgs[min_idxs[0]] + 1) / 2).detach().cpu().numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(((imgs[min_idxs[1]] + 1) / 2).detach().cpu().numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distances[np.tril_indices(distances.shape[0])] = -np.inf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_idxs = np.unravel_index(distances.argmax(), distances.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distances[max_idxs]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(((imgs[max_idxs[0]] + 1) / 2).detach().cpu().numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(((imgs[max_idxs[1]] + 1) / 2).detach().cpu().numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция тестирования: https://github.com/deepinsight/insightface/blob/32682e54e08f36216bdf82dd9e03512c63cbac5c/recognition/arcface_torch/eval/verification.py#L179"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
