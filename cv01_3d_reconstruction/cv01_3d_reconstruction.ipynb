{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "В рамках выполнения данного задания вам необходимо создать панораму вашей комнаты. Панорама должна состоять минимум из 5 изображений. Они должны быть сняты таким образом, чтобы любое из них имело пересечение не более, чем с двумя другими\n",
    "\n",
    "Баллы будут проставлены следующим образом:\n",
    "* До 7 баллов за построение панорамы (зависит от её итогового качества)\n",
    "* 3 балла за самостоятельную имплементацию любого из рассмотренных на лекции или семинаре алгоритма"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install opencv-python matplotlib numpy ipython-autotime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import math\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "matplotlib.use('TkAgg')  # for macOS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20.0, 16.0)\n",
    "plt.rcParams['image.interpolation'] = 'bilinear'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Panorama stitching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = 'input'\n",
    "ipaths = sorted(glob.glob(osp.join(input_dir, 'img_*.jpg')))\n",
    "n_imgs = len(ipaths)\n",
    "\n",
    "images_info = dict()\n",
    "for i_num, ipath in enumerate(ipaths):\n",
    "    img = plt.imread(ipath)\n",
    "    images_info[ipath] = {'img': img}\n",
    "    plt.subplot(1, n_imgs, i_num + 1)\n",
    "    plt.title(osp.basename(ipath), fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images_info[ipath]['img'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keypoints detection + descriptors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def keypoints_detection_sift(input_img):\n",
    "    gray = cv2.cvtColor(input_img, cv2.COLOR_RGB2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kps, dscrs = sift.detectAndCompute(gray, None)\n",
    "    return kps, dscrs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i_num, ipath in enumerate(images_info):\n",
    "    img = images_info[ipath]['img']\n",
    "    keypoints, descriptors = keypoints_detection_sift(img)\n",
    "    images_info[ipath]['keypoints'] = keypoints\n",
    "    images_info[ipath]['descriptors'] = descriptors\n",
    "    plt.subplot(1, n_imgs, i_num + 1)\n",
    "    plt.title(osp.basename(ipaths[i_num]), fontsize=20)\n",
    "    plt.imshow(cv2.drawKeypoints(\n",
    "        img, keypoints, None,\n",
    "        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "    ))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keypoints, descriptors = images_info[ipaths[0]]['keypoints'], \\\n",
    "    images_info[ipaths[0]]['descriptors']\n",
    "keypoint = sorted(keypoints, key=lambda x: x.size, reverse=True)[0]\n",
    "for field in dir(keypoint):\n",
    "    if not field.startswith('_'):\n",
    "        print(f'{field:10} {getattr(keypoint, field)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.drawKeypoints(\n",
    "    images_info[ipaths[0]]['img'], [keypoint, ], None,\n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keypoints matching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bruteforce + Cross-check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def keypoints_matching_cross_check(dscrs1, dscrs2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    cross_matches = bf.match(dscrs1, dscrs2)\n",
    "    return cross_matches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches = keypoints_matching_cross_check(\n",
    "    images_info[ipaths[0]]['descriptors'],\n",
    "    images_info[ipaths[1]]['descriptors']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_matches = cv2.drawMatches(\n",
    "    images_info[ipaths[0]]['img'],\n",
    "    images_info[ipaths[0]]['keypoints'],\n",
    "    images_info[ipaths[1]]['img'],\n",
    "    images_info[ipaths[1]]['keypoints'],\n",
    "    matches,\n",
    "    None,  # output image\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    ")\n",
    "plt.imshow(img_matches)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN + Ratio test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def keypoints_matching_knn(dscrs1, dscrs2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    tic = time.time_ns()\n",
    "    knn_matches = bf.knnMatch(dscrs1, dscrs2, k=2)\n",
    "    toc = time.time_ns()\n",
    "    print(f'Matching time: {(toc - tic) / 10e6 :.5f} ms')\n",
    "    good_matches = []\n",
    "    for neighbour_1, neighbour_2 in knn_matches:\n",
    "        if neighbour_1.distance < 0.75 * neighbour_2.distance:\n",
    "            good_matches.append(neighbour_1)\n",
    "    return good_matches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches = keypoints_matching_knn(\n",
    "    images_info[ipaths[0]]['descriptors'],\n",
    "    images_info[ipaths[1]]['descriptors']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_matches = cv2.drawMatches(\n",
    "    images_info[ipaths[0]]['img'],\n",
    "    images_info[ipaths[0]]['keypoints'],\n",
    "    images_info[ipaths[1]]['img'],\n",
    "    images_info[ipaths[1]]['keypoints'],\n",
    "    matches,\n",
    "    None,  # output image\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    ")\n",
    "plt.imshow(img_matches)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FLANN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def keypoints_matching_flann(dscrs1, dscrs2):\n",
    "    index_params = dict(\n",
    "        algorithm=1,  # FLANN_INDEX_KDTREE\n",
    "        trees=5\n",
    "    )\n",
    "    search_params = dict(checks=20)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    tic = time.time_ns()\n",
    "    flann_matches = flann.knnMatch(dscrs1, dscrs2, k=2)\n",
    "    toc = time.time_ns()\n",
    "    print(f'Matching time: {(toc - tic) / 10e6 :.5f} ms')\n",
    "    good_matches = []\n",
    "    for neighbour_1, neighbour_2 in flann_matches:\n",
    "        if neighbour_1.distance < 0.75 * neighbour_2.distance:\n",
    "            good_matches.append(neighbour_1)\n",
    "    return good_matches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches = keypoints_matching_flann(\n",
    "    images_info[ipaths[0]]['descriptors'],\n",
    "    images_info[ipaths[1]]['descriptors']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_matches = cv2.drawMatches(\n",
    "    images_info[ipaths[0]]['img'],\n",
    "    images_info[ipaths[0]]['keypoints'],\n",
    "    images_info[ipaths[1]]['img'],\n",
    "    images_info[ipaths[1]]['keypoints'],\n",
    "    matches,\n",
    "    None,  # output image\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    ")\n",
    "plt.imshow(img_matches)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Descriptors shape on the image_0: {images_info[ipaths[0]][\"descriptors\"].shape}')\n",
    "print(f'Descriptors shape on the image_1: {images_info[ipaths[1]][\"descriptors\"].shape}')\n",
    "mock_descriptors_1 = np.repeat(images_info[ipaths[0]]['descriptors'], 100, axis=0)\n",
    "mock_descriptors_2 = np.repeat(images_info[ipaths[1]]['descriptors'], 100, axis=0)\n",
    "print(f'Descriptors shape on the mock_image_0: {mock_descriptors_1.shape}')\n",
    "print(f'Descriptors shape on the mock_image_1: {mock_descriptors_2.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = keypoints_matching_knn(mock_descriptors_1, mock_descriptors_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = keypoints_matching_flann(mock_descriptors_1, mock_descriptors_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find matches for images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches_images = dict()\n",
    "for ipath_0, ipath_1 in itertools.permutations(ipaths, 2):\n",
    "    matches_pair = keypoints_matching_knn(\n",
    "        images_info[ipath_0]['descriptors'],\n",
    "        images_info[ipath_1]['descriptors']\n",
    "    )\n",
    "    matches_images[(ipath_0, ipath_1)] = matches_pair"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Homography"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "homographies = dict()\n",
    "for (ipath_0, ipath_1), matches in matches_images.items():\n",
    "    src_pts = np.float32(\n",
    "        [images_info[ipath_0]['keypoints'][m.queryIdx].pt for m in matches]\n",
    "    ).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32(\n",
    "        [images_info[ipath_1]['keypoints'][m.trainIdx].pt for m in matches]\n",
    "    ).reshape(-1, 1, 2)\n",
    "    M, mask = cv2.findHomography(\n",
    "        src_pts,\n",
    "        dst_pts,\n",
    "        cv2.RANSAC,\n",
    "        ransacReprojThreshold=.5,\n",
    "        maxIters=20000,\n",
    "        confidence=0.995\n",
    "    )\n",
    "    homographies[ipath_0, ipath_1] = (M, mask.ravel().tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ipath_0, ipath_1 in itertools.permutations(ipaths, 2):\n",
    "    matches = matches_images[ipath_0, ipath_1]\n",
    "    M, matches_mask = homographies[ipath_0, ipath_1]\n",
    "    img_0, img_1_polylines = images_info[ipath_0]['img'].copy(), \\\n",
    "        images_info[ipath_1]['img'].copy()\n",
    "    rows_0, cols_0 = img_0.shape[:2]\n",
    "    rows_1, cols_1 = img_1_polylines.shape[:2]\n",
    "    pts = np.float32(\n",
    "        [[0, 0], [0, rows_0], [cols_0, rows_0], [cols_0, 0]]).reshape(-1, 1, 2)\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "    img_1_polylines = cv2.polylines(\n",
    "        img_1_polylines, [np.int32(dst)], True, 255, 3, cv2.LINE_AA\n",
    "    )\n",
    "    img_matches = cv2.drawMatches(\n",
    "        img_0,\n",
    "        images_info[ipath_0]['keypoints'],\n",
    "        img_1_polylines,\n",
    "        images_info[ipath_1]['keypoints'],\n",
    "        matches,\n",
    "        None,  # output image\n",
    "        matchesMask=matches_mask,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "    )\n",
    "    plt.title(\n",
    "        f'Pair of images: {ipath_0} and {ipath_1} ({sum(matches_mask)} matches)',\n",
    "        fontsize=20\n",
    "    )\n",
    "    plt.imshow(img_matches)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stitching images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "M, _ = homographies[ipaths[1], ipaths[0]]\n",
    "img_0, img_1 = images_info[ipaths[0]]['img'], images_info[ipaths[1]]['img']\n",
    "img_0_1 = cv2.warpPerspective(\n",
    "    img_1, M, (img_0.shape[1] + img_1.shape[1], img_1.shape[0])\n",
    ")\n",
    "img_0_1[0:img_0.shape[0], 0:img_0.shape[1]] = img_0\n",
    "\n",
    "# Some postprocessing\n",
    "img_0_1_mask = np.where(img_0_1.sum(axis=2) != 0, 1, 0).astype('uint8')\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "img_0_1_mask = cv2.morphologyEx(img_0_1_mask, cv2.MORPH_CLOSE, kernel)\n",
    "img_0_1_mask = cv2.erode(img_0_1_mask, kernel, iterations=1)\n",
    "img_0_1_mask = np.dstack([img_0_1_mask, ] * 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(img_0_1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "M, _ = homographies[ipaths[2], ipaths[0]]\n",
    "img_2 = images_info[ipaths[2]]['img']\n",
    "img_2_pano = cv2.warpPerspective(\n",
    "    img_2, M, (img_0.shape[1] + img_1.shape[1], img_1.shape[0])\n",
    ")\n",
    "panorama = np.where(img_0_1_mask != 0, img_0_1, img_2_pano)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(panorama)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Camera calibration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для калибровки камер мы будем использовать специальный паттерн, который называется шахматная доска. Его параметры нам хорошо известны, поэтому с его помощью откалибровать камеру будет проще, чем через пайплайн, который мы использовали для построения панорамы.\n",
    "Изображение chessboard можно найти в поставке opencv на [github](https://github.com/opencv/opencv/blob/4.x/samples/data/chessboard.png)\n",
    "Его необходимо распечатать и сфотографировать с разных углов и расстояний, чтобы получить достаточное количество изображений для калибровки камеры. Суммарное количество изображений должно быть не менее 10."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_dir = 'input'\n",
    "chessboard_ipaths = sorted(glob.glob(osp.join(input_dir, 'chessboard_*.jpg')))\n",
    "n_chessboard_imgs = len(chessboard_ipaths)\n",
    "print(f'Number of chessboard images: {n_chessboard_imgs}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "На каждом изображении необходимо найти углы шахматной доски. Для этого используется функция `cv2.findChessboardCorners`. С помощью этой функции мы получим соответствие между углами шахматной доски в реальном мире (object points) и точками на изображении (image points)\n",
    "После нахождения углов их местоположение можно доуточнить с помощью функции `cv2.cornerSubPix`. Вы можете воспользоваться этой функцией, если вам будет недостаточно получаемого без неё качества калибровки."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "objp = np.zeros((6 * 9, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "# Arrays to store object points and image points from all the images\n",
    "obj_points = []  # 3d points in real world space\n",
    "img_points = []  # 2d points in image plane."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 36))\n",
    "for i_num, ipath in enumerate(chessboard_ipaths):\n",
    "    img = cv2.cvtColor(cv2.imread(ipath), cv2.COLOR_BGR2RGB)\n",
    "    img_grayscale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    result, corners = cv2.findChessboardCorners(img_grayscale, (9, 6), None)\n",
    "    if result:\n",
    "        obj_points.append(objp)\n",
    "        img_points.append(corners)\n",
    "\n",
    "        cv2.drawChessboardCorners(img, (9, 6), corners, result)\n",
    "        plt.subplot(math.ceil(n_chessboard_imgs / 3), 3, i_num + 1)\n",
    "        plt.title(osp.basename(ipath), fontsize=12)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Имея соответствие между углами шахматной доски в реальном мире и точками на изображении, можно калибровать камеру. Для этого используется функция `cv2.calibrateCamera`. В результате калибровки мы получим матрицу камеры и коэффициенты дисторсии."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(chessboard_ipaths[-1]), cv2.COLOR_BGR2RGB)\n",
    "img_grayscale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "result, mtx, dist, r_vecs, t_vecs = cv2.calibrateCamera(\n",
    "    objectPoints=obj_points,\n",
    "    imagePoints=img_points,\n",
    "    imageSize=img_grayscale.shape[::-1],\n",
    "    cameraMatrix=None,\n",
    "    distCoeffs=None\n",
    ")\n",
    "print(f'Camera matrix:\\n{mtx}')\n",
    "print(f'Distortion coefficients:\\n{dist}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.savetxt('mtx.txt', mtx)\n",
    "np.savetxt('dist.txt', dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Эти параметры можно использовать для коррекции изображений, полученных с данной камеры. Для этого используется функция `cv2.undistort`. При этом можно использовать функцию `cv2.getOptimalNewCameraMatrix`, чтобы получить новую матрицу камеры. Она будет содержать только те пиксели, которые содержат информацию об изображении."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows, cols = img.shape[:2]\n",
    "new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(\n",
    "    cameraMatrix=mtx,\n",
    "    distCoeffs=dist,\n",
    "    imageSize=(cols, rows),\n",
    "    alpha=1,\n",
    "    newImgSize=(cols, rows)\n",
    ")\n",
    "print(f'New camera matrix:\\n{new_camera_mtx}')\n",
    "print(f'Region of interest:\\n{roi}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dst = cv2.undistort(\n",
    "    src=img,\n",
    "    cameraMatrix=mtx,\n",
    "    distCoeffs=dist,\n",
    "    dst=None,\n",
    "    newCameraMatrix=new_camera_mtx\n",
    ")\n",
    "\n",
    "plt.imshow(dst)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roi_x, roi_y, roi_w, roi_h = roi\n",
    "dst = dst[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w]\n",
    "plt.imshow(dst)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
